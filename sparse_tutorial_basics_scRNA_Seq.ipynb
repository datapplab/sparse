{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sparse_tutorial_basics_scRNA-Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMcwjQyDUuw5"
      },
      "source": [
        "#Preparation\n",
        "\n",
        "Mount your Google Drive when using Google Colab. This is not needed when running this notebook locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BovRrd0cRds7",
        "outputId": "e20f8292-d432-4f8e-c05c-7b415d03709a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvH1XAgTWBoq"
      },
      "source": [
        "Download sparsenet package from GitHub. Note you need to have Python 3 (and NumPy) and TensorFlow 2.0 or above installed first. Commands under Linux and Colab:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbef9DQcWAx9",
        "outputId": "ac0d872c-ba14-41f8-c5e4-ecbe4347dace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%%bash\n",
        "# pip install --upgrade tensorflow\n",
        "cd /content/drive/My\\ Drive/packages\n",
        "git clone https://github.com/datapplab/sparsenet.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sparsenet'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXTOAv98_mIt"
      },
      "source": [
        "Alternatively, you can pip install sparsenet package from GitHub. This will also install the dependencies, eg TensorFlow and NumPy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlmkMHs5_T4B"
      },
      "source": [
        "!pip install git+https://github.com/datapplab/sparsenet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bCOG_uGVSvx"
      },
      "source": [
        "Import dependencies for this notebook. Please edit the path to sparsenet package downloaded. You don't need the `sys.path.append` line if the package was installed instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgdeN-BwGMKu",
        "outputId": "17aeb96f-a0eb-4de6-e8dd-067c59e567fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import random\n",
        "import os\n",
        "\n",
        "# import tf 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/packages/sparsenet')\n",
        "from sparsenet.core import sparse"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "#Real single cell RNA-Seq dataset--BSEQ\n",
        "\n",
        "[BSEQ](https://shenorrlab.github.io/bseqsc/vignettes/bseq-sc.html) is a scRNA-Seq dataset on individual human pancreatic islets cells. This processed dataset include 1822 cells and the top 1000 genes with the biggest variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSgoq-dUmIZu"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "Load and prepare the BSEQ dataset, and split it into training and validation sets by ratio of 2/3 and 1/3. Note testing set is the same as validation set here. Again, please edit the path to sparse module installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isg0jwAM-zvN"
      },
      "source": [
        "# change the path to your own\n",
        "infile= \"/content/drive/My Drive/packages/sparse/data/bseq.tsv\"\n",
        "bseq1 = pd.read_csv(infile,sep=\"\\t\", header=0, index_col=0)\n",
        "X = bseq1.values\n",
        "nfs=X.shape[1]\n",
        "y=X[:,nfs-1] -1\n",
        "X = X[:,:nfs-1]\n",
        "y=y.astype(int)\n",
        "ns=y.size\n",
        "idx=np.arange(ns)\n",
        "np.random.seed(1)\n",
        "idx1=np.random.choice(idx, size=ns, replace=False)\n",
        "X=X[idx1]\n",
        "y=y[idx1]\n",
        "n_train = round(ns*2/3)\n",
        "n_val = round(ns*1/3)\n",
        "X_train = X[:n_train]\n",
        "X_val   = X[n_train:n_train+n_val]\n",
        "X_test= X_val\n",
        "y_train = y[:n_train]\n",
        "y_val   = y[n_train:n_train+n_val]\n",
        "y_test=y_val\n",
        "n_values = np.max(y_train) + 1\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_AHUDjUnQGU"
      },
      "source": [
        "## Classic dense neural network or multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build a `tf.keras.Sequential` model with two dense layers. Alternatively, you can use 1 or 2 sparse layers in place of the dense layer(s) as in commented code. Choose an optimizer and loss function for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo",
        "outputId": "d4f5ce68-5415-4b67-8a12-dc07d3374399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "nunits=250\n",
        "dens=0.1\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=X_train.shape[1]),\n",
        "  tf.keras.layers.Dense(nunits, activation=None),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  # sparse(units=nunits, density=dens, activation=None),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "  # sparse(units=10, density=0.4, activation='softmax'),\n",
        "])\n",
        "\n",
        "lr=1e-3\n",
        "optimizer = tf.keras.optimizers.Nadam(lr =lr)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, \n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 23.6434 - accuracy: 0.3210 - val_loss: 14.1590 - val_accuracy: 0.3773\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.4835 - accuracy: 0.5210 - val_loss: 8.6665 - val_accuracy: 0.5783\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6074 - accuracy: 0.7572 - val_loss: 1.8743 - val_accuracy: 0.8929\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9038 - accuracy: 0.8206 - val_loss: 0.7987 - val_accuracy: 0.9012\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.9226 - val_loss: 0.1792 - val_accuracy: 0.9736\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.9358 - val_loss: 0.1511 - val_accuracy: 0.9720\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9663 - val_loss: 0.1617 - val_accuracy: 0.9753\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.4247 - accuracy: 0.8181 - val_loss: 4.8741 - val_accuracy: 0.5832\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0926 - accuracy: 0.9276 - val_loss: 0.1558 - val_accuracy: 0.9753\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9770 - val_loss: 0.0937 - val_accuracy: 0.9868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a26688d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJW70PhIYqjS"
      },
      "source": [
        "Model summary info, note the number of parameters is much bigger than that in model with sparse layers below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuDx_j-Y42ZN",
        "outputId": "ca82fdfb-2bc3-4280-b084-ea5c1c13f441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 250)               250250    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2510      \n",
            "=================================================================\n",
            "Total params: 252,760\n",
            "Trainable params: 252,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfVZwmVdYyzj"
      },
      "source": [
        "## Sparse neural network or multilayer perceptron (MLP)\n",
        "\n",
        "Build a `tf.keras.Sequential` model with two sparse layers. Alternatively, you can use 1 dense layer as in the commented code or 2 dense layers as shown above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDFS45uc4XFC",
        "outputId": "aecf9b2f-c20c-464d-c70b-aa8c9999b7df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "nunits=250\n",
        "dens1=0.1\n",
        "dens2=0.4\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=X_train.shape[1]),\n",
        "  sparse(units=nunits, density=dens1, activation=None),\n",
        "  # tf.keras.layers.Dense(10, activation='softmax')\n",
        "  sparse(units=10, density=dens2, activation='softmax'),\n",
        "])\n",
        "\n",
        "lr=1e-3\n",
        "optimizer = tf.keras.optimizers.Nadam(lr =lr)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight_type used:  1\n",
            "weight_type used:  1\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.5001 - accuracy: 0.4255 - val_loss: 1.1297 - val_accuracy: 0.6474\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9788 - accuracy: 0.6831 - val_loss: 0.6686 - val_accuracy: 0.8567\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.8313 - val_loss: 0.5243 - val_accuracy: 0.8979\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8897 - val_loss: 0.4995 - val_accuracy: 0.8517\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.9193 - val_loss: 0.2487 - val_accuracy: 0.9209\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2343 - accuracy: 0.9424 - val_loss: 0.1948 - val_accuracy: 0.9753\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9745 - val_loss: 0.1365 - val_accuracy: 0.9769\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9819 - val_loss: 0.1205 - val_accuracy: 0.9819\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9778 - val_loss: 0.0985 - val_accuracy: 0.9901\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9893 - val_loss: 0.1005 - val_accuracy: 0.9852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a2645db00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MHOeUwNg4Yv"
      },
      "source": [
        "Model summary info, note the number of parameters is ~1/10 of that in model with dense layers above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om2Z0uRrCH0g",
        "outputId": "45771994-3d3a-4854-d24e-fb2f571c2e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sparse (sparse)              (None, 250)               25250     \n",
            "_________________________________________________________________\n",
            "sparse_1 (sparse)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 26,260\n",
            "Trainable params: 26,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7toyPvNZdug"
      },
      "source": [
        "## Sparse Autoencode\n",
        "\n",
        "Simple autoencoder using sparse layers, alternative autoencoder using dense layers in code commented out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHBv9i4SCKhF",
        "outputId": "11f8f055-bb4e-4801-e689-14f2f9a43349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "nin=X_train.shape[1]\n",
        "nunits=128\n",
        "dens=0.5\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=nin),\n",
        "  # tf.keras.layers.Dense(nunits, activation=None),\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  # tf.keras.layers.Dense(nin, activation=None)\n",
        "  sparse(units=nunits, density=dens, activation=None),\n",
        "  sparse(units=nin, density=dens, activation=None),\n",
        "])\n",
        "\n",
        "lr=1e-3\n",
        "optimizer = tf.keras.optimizers.Nadam(lr =lr)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ns=12000\n",
        "model.fit(X_train, X_train, epochs=20, batch_size=64, \n",
        "          validation_data=(X_test, X_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight_type used:  1\n",
            "weight_type used:  1\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 15.3974 - accuracy: 0.0025 - val_loss: 3.9371 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 3.9001 - accuracy: 0.0058 - val_loss: 3.9044 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.7590 - accuracy: 0.0058 - val_loss: 3.4935 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.3526 - accuracy: 0.0428 - val_loss: 3.1424 - val_accuracy: 0.0362\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.1234 - accuracy: 0.1819 - val_loss: 2.9699 - val_accuracy: 0.0824\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.9868 - accuracy: 0.1868 - val_loss: 3.1414 - val_accuracy: 0.3410\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.0221 - accuracy: 0.2337 - val_loss: 3.0148 - val_accuracy: 0.3526\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.1357 - accuracy: 0.2807 - val_loss: 3.5140 - val_accuracy: 0.3723\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.1209 - accuracy: 0.3078 - val_loss: 2.8297 - val_accuracy: 0.4036\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.8105 - accuracy: 0.3621 - val_loss: 2.8577 - val_accuracy: 0.3311\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.8550 - accuracy: 0.3877 - val_loss: 2.9154 - val_accuracy: 0.4135\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.8545 - accuracy: 0.4280 - val_loss: 2.7888 - val_accuracy: 0.4761\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.1431 - accuracy: 0.4634 - val_loss: 3.2854 - val_accuracy: 0.4596\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.9056 - accuracy: 0.4593 - val_loss: 2.8072 - val_accuracy: 0.4168\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.6834 - accuracy: 0.4815 - val_loss: 2.6191 - val_accuracy: 0.5371\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.6560 - accuracy: 0.5086 - val_loss: 2.6637 - val_accuracy: 0.5206\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.8645 - accuracy: 0.5029 - val_loss: 3.0532 - val_accuracy: 0.4695\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.0081 - accuracy: 0.4996 - val_loss: 2.8351 - val_accuracy: 0.5272\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.7885 - accuracy: 0.5029 - val_loss: 2.5923 - val_accuracy: 0.5420\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.5746 - accuracy: 0.5292 - val_loss: 2.5554 - val_accuracy: 0.5255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91f6f68e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmhcL1ZVZzO1"
      },
      "source": [
        "#Simulated single cell RNA-Seq dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qx5LJvKoy-3"
      },
      "source": [
        "\n",
        "## Data preparation\n",
        "\n",
        "Similar analysis using a simulated scRNA-Seq dataset. Read in and prepare the input data first. Note you need to modified the file paths based on your own setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQV1mDSeEQmY",
        "outputId": "efdd5d67-5937-446b-d2dd-ae2f19b771dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# import pandas as pd\n",
        "expr = pd.read_csv('/content/drive/My Drive/packages/sparsenet/data/Dataset1/counts.csv',index_col=0)\n",
        "expr_true = pd.read_csv('/content/drive/My Drive/packages/sparsenet/data/Dataset1/truecounts.csv',index_col=0)\n",
        "cellinfo = pd.read_csv('/content/drive/My Drive/packages/sparsenet/data/Dataset1/cellinfo.csv',index_col=0)\n",
        "X = expr.values #Splash generated scRNA-seq data with dropout\n",
        "X_true = expr_true.values #Splash generated scRNA-seq data without dropout (ground truth)\n",
        "Y = cellinfo['Group'].values #cell type label\n",
        "cnames, Y1 = np.unique(Y, return_inverse=True)\n",
        "unique_class = np.unique(Y)\n",
        "celltypes = Y\n",
        "nclass = len(unique_class)\n",
        "ncell,ngene = X.shape\n",
        "print('{} genes, {} cells in {} groups'.format(ngene,ncell,nclass))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938 genes, 500 cells in 6 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paC6hlSqcMIU"
      },
      "source": [
        "##Classic neural network or multilayer perceptron (MLP)\n",
        "\n",
        "Build a tf.keras.Sequential model with two dense layers. Alternatively, you can use 1 or 2 sparse layers in place of the dense layer(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efdv65YIK6ao",
        "outputId": "b2425e29-601e-4d2e-b588-d3b499f02119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "nn=125\n",
        "nclass=6\n",
        "nepoch=10\n",
        "bs=32\n",
        "lr=1e-3\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=X.shape[1]),\n",
        "  tf.keras.layers.Dense(units=nn, activation=None),#'relu'\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(units=nclass, activation='softmax'),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam(lr =lr)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "ns=400\n",
        "hist=model.fit(X[:ns], Y1[:ns], epochs=nepoch, batch_size=bs, validation_data=(X[ns:], Y1[ns:]))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 301.7191 - accuracy: 0.1575 - val_loss: 239.6888 - val_accuracy: 0.2300\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 228.3411 - accuracy: 0.1800 - val_loss: 117.6474 - val_accuracy: 0.2100\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 127.9130 - accuracy: 0.3500 - val_loss: 107.7679 - val_accuracy: 0.3700\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 140.5288 - accuracy: 0.3700 - val_loss: 32.0104 - val_accuracy: 0.6500\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 28.4050 - accuracy: 0.7100 - val_loss: 8.0014 - val_accuracy: 0.8100\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 8.6838 - accuracy: 0.8700 - val_loss: 10.7696 - val_accuracy: 0.7800\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 13.7377 - accuracy: 0.8175 - val_loss: 5.7912 - val_accuracy: 0.8500\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.6329 - accuracy: 0.9050 - val_loss: 24.7754 - val_accuracy: 0.6900\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7152 - accuracy: 0.8925 - val_loss: 0.2191 - val_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1.2335 - accuracy: 0.9650 - val_loss: 2.1466 - val_accuracy: 0.9300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3h34oBicxdQ"
      },
      "source": [
        "##Sparse neural network or multilayer perceptron (MLP)\n",
        "\n",
        "Build a `tf.keras.Sequential` model with two sparse layers. Alternatively, you can use 1 dense layer as in the commented code or 2 dense layers as shown above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CacE-jR7b5I",
        "outputId": "29181b35-8fc4-4a04-d88c-b6dce659c0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "dens1=0.2\n",
        "dens2=0.4\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=X.shape[1]),\n",
        "  sparse(units=nn, density=dens1, activation=None),\n",
        "  # tf.keras.layers.Dense(nclass, activation='softmax')\n",
        "  sparse(units=nclass, density=dens2, activation='softmax'),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam(lr =lr)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist=model.fit(X[:ns], Y1[:ns], epochs=nepoch, batch_size=bs, validation_data=(X[ns:], Y1[ns:]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight_type used:  1\n",
            "weight_type used:  1\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 13.2753 - accuracy: 0.1700 - val_loss: 11.9290 - val_accuracy: 0.1800\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 10.5287 - accuracy: 0.2275 - val_loss: 6.6976 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.7059 - accuracy: 0.2875 - val_loss: 7.3942 - val_accuracy: 0.4400\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.7646 - accuracy: 0.7050 - val_loss: 0.9430 - val_accuracy: 0.7100\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9575 - val_loss: 0.1731 - val_accuracy: 0.9900\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9850 - val_loss: 0.1400 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9975 - val_loss: 0.1196 - val_accuracy: 0.9900\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9975 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CszET4Ux7MN5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}